{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"COVID19 - One Step Ahead Prediction","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tJwnF8Ff1gzG","colab_type":"text"},"source":["**One Step Ahead Prediction**"]},{"cell_type":"code","metadata":{"id":"Y-rwyRsGkbl8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":530},"outputId":"a5f9249d-db30-4fce-cb1f-fc4fa9f4f4dc"},"source":["# Lib\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import AdaBoostRegressor\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","# Plotting graph\n","def plotGraph3(ref, mdl, varName):\n","    plt.figure()\n","    plt.plot(np.ravel(ref), 'g')\n","    plt.plot(mdl, 'r')\n","    plt.title(varName)\n","    plt.ylabel('Number of infected people')\n","    plt.xlabel('Data points')\n","    plt.show()\n","\n","# Finding RMSE\n","def ErrorCalc(mdl, ref, tag):\n","    relError = np.abs(mdl - ref)/ np.abs(ref+1)\n","    MeanErrorV = np.mean(relError)\n","    print(tag + ': Mean Rel Error in %: ', MeanErrorV * 100)\n","    return MeanErrorV\n","\n","# Since cumulative prediction\n","def AdjustingErrorsOutliers(tempPred, df) :\n","    tempPred = np.round(tempPred)\n","    tempPrev = df['day5'].to_numpy() # Next cumulative prediction must be more than or equal to previous\n","    for i in range(len(tempPred)):\n","        if tempPred[i] < tempPrev[i] : # Since cumulative prediction\n","            tempPred[i] = tempPrev[i]\n","    return tempPred\n","\n","# Train model\n","def TrainMdl (trainIpData, trainOpData, PredictionData) :\n","    testSize = 0.1 # 90:10 ratio >> for final testing\n","    #randomState = 42 # For train test split\n","\n","    print('Training starts ...')\n","\n","    totalIte = 10\n","\n","    for iLoop in range(totalIte):\n","\n","        if iLoop == 0 :\n","            randomState = 42\n","        else :\n","            randomState=None\n","\n","\n","        # Final validation\n","        X_train, X_test, y_train, y_test = train_test_split(trainIpData, trainOpData, test_size=testSize, random_state=randomState)\n","\n","        # Extrating features\n","        TrainIP = X_train[['diff1', 'diff2', 'diff3', 'diff4', 'tempVal', 'ageVal']]\n","        TrainOP = X_train['gammaFun']\n","        TestIP = X_test[['diff1', 'diff2', 'diff3', 'diff4', 'tempVal', 'ageVal']]\n","        TestOP = X_test['gammaFun']\n","\n","\n","        # Adaboost Regressor >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","        treeDepth = 10 # Fixed\n","        mdl = DecisionTreeRegressor(max_depth=treeDepth) # This is fixed\n","        param_grid = {\n","        'n_estimators': [10, 50, 100, 250, 500],\n","        'learning_rate': [0.3, 0.2, 0.1, 0.01, 0.001]\n","                    }\n","        regrMdl = AdaBoostRegressor(base_estimator=mdl)\n","        clf = RandomizedSearchCV(estimator = regrMdl, param_distributions = param_grid,\n","                                         n_iter = 100, cv = 3, verbose=0, random_state=42, n_jobs = -1)\n","        clf.fit(TrainIP, TrainOP)\n","\n","\n","        # Calculating Error >> X_train is a superset of TrainIP\n","        y_predictedTrain = clf.predict(TrainIP) # Predicting the gamma function\n","        y_predictedTrain = AdjustingErrorsOutliers(y_predictedTrain * X_train['day5'].to_numpy(), X_train)\n","        ErrorCalc(y_predictedTrain, y_train.to_numpy(), 'Train Data-set') # y_predictedTrain converted to numbers\n","\n","        y_predictedTest = clf.predict(TestIP) # Predicting the gamma function\n","        y_predictedTest = AdjustingErrorsOutliers(y_predictedTest * X_test['day5'].to_numpy(), X_test)\n","        ErrorCalc(y_predictedTest, y_test.to_numpy(), 'Validation Data-set ') # y_predictedTest converted to numbers\n","\n","        print('-----------------------------------------------------------')\n","\n","        # Extrating primary features\n","        PredictionDataF = PredictionData[['diff1', 'diff2', 'diff3', 'diff4', 'tempVal', 'ageVal']]\n","\n","        # Prediction\n","        if iLoop == 0 :\n","            finalPrediction = clf.predict(PredictionDataF)  # Predicting the gamma function\n","            tempPred = finalPrediction * PredictionData['day5'].to_numpy()\n","            y_predictedFinal0 = AdjustingErrorsOutliers(tempPred, PredictionData)\n","        else :\n","            finalPrediction = clf.predict(PredictionDataF)  # Predicting the gamma function\n","            tempPred = finalPrediction * PredictionData['day5'].to_numpy()\n","            y_predictedFinal = AdjustingErrorsOutliers(tempPred, PredictionData)\n","            y_predictedFinal0 = y_predictedFinal0 + y_predictedFinal\n","\n","    y_predictedFinal0 = np.round(y_predictedFinal0 / totalIte)\n","    return y_predictedFinal0\n","\n","\n","# Main code starts\n","# Settings\n","displayAll = 1\n","if displayAll == 1 :\n","    pd.set_option('display.max_columns', None)\n","\n","# Adjust John Hopkins Dataset\n","worldCorona = pd.read_csv('https://raw.githubusercontent.com/neilay-khasnabish/COVID-20/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n","worldCorona = worldCorona.fillna(0)\n","worldCorona = worldCorona.drop(['Province/State'], axis=1)\n","worldCorona['Country'] = worldCorona['Country/Region']\n","worldCorona = worldCorona.drop(['Country/Region', 'Lat', 'Long'], axis=1)\n","worldCorona = worldCorona.groupby(['Country']).sum()\n","worldCorona.to_csv('Hellos.csv')\n","worldCorona = pd.read_csv('Hellos.csv')\n","\n","# Total countries in the world\n","totalCountries = pd.read_csv('https://raw.githubusercontent.com/neilay-khasnabish/COVID-19/master/WorldCountryNames.csv')\n","print('Countries infected: ', np.shape(worldCorona)[0], '/', np.shape(totalCountries)[0])\n","\n","# Countrywise temperature\n","countryTemp = pd.read_csv('https://raw.githubusercontent.com/neilay-khasnabish/COVID-19/master/Temp.csv')\n","\n","# Countrywise age\n","countryAge = pd.read_csv('https://raw.githubusercontent.com/neilay-khasnabish/COVID-19/master/MedAge.csv')\n","\n","# Merging all three\n","result1 = pd.merge(worldCorona, countryTemp, on='Country').reset_index(drop=True)\n","result = pd.merge(result1, countryAge, on='Country').reset_index(drop=True)\n","print('Final size of merged data (rows equal to number of countries to be processed): ', np.shape(result))\n","result.to_csv('hellow.csv')\n","\n","# Creating dataframe for training\n","[rf, cf] = np.shape(result)\n","print('Row', rf, '| Col: ', cf)\n","df=[]\n","for i in range(rf): # It scans through the entire row\n","    iCol = 6 # Start index\n","    while iCol <= cf-4 :\n","        dayPredict = result.iloc[i, iCol+1]\n","        day5 = result.iloc[i, iCol]\n","        day4 = result.iloc[i, iCol-1]\n","        day3 = result.iloc[i, iCol-2]\n","        day2 = result.iloc[i, iCol-3]\n","        day1 = result.iloc[i, iCol-4]\n","        diff1 = day5 - day4\n","        diff2 = day4 - day3\n","        diff3 = day3 - day2\n","        diff4  = day2 - day1\n","        iCol = iCol + 1\n","        ageVal = result.iloc[i, cf - 1]\n","        tempVal = result.iloc[i, cf - 2]\n","        dividen = day5 + 1\n","        gammaFun = dayPredict / dividen\n","        data = {'day1': [day1], 'day2': [day2], 'day3': [day3], 'day4': [day4], 'day5': [day5], 'tempVal': [tempVal], 'ageVal': [ageVal],\n","                'dayPredict': [dayPredict], 'gammaFun': [gammaFun], 'diff1': [diff1], 'diff2': [diff2], 'diff3': [diff3], 'diff4': [diff4]}\n","        df2 = pd.DataFrame(data)\n","        df.append(df2)\n","\n","df = pd.concat(df).reset_index(drop=True)\n","df = df.fillna(0)\n","df.to_csv('TrainTest.csv')\n","\n","# Preparing real-time prediction data\n","dfP=[]\n","for i in range(rf): # It scans through the entire row\n","    day5 = result.iloc[i, cf - 3]\n","    day4 = result.iloc[i, cf - 4]\n","    day3 = result.iloc[i, cf - 5]\n","    day2 = result.iloc[i, cf - 6]\n","    day1 = result.iloc[i, cf - 7]\n","    diff1 = day5 - day4\n","    diff2 = day4 - day3\n","    diff3 = day3 - day2\n","    diff4 = day2 - day1\n","    ageVal = result.iloc[i, cf - 1]\n","    tempVal = result.iloc[i, cf - 2]\n","    countryName = result.iloc[i, 0]\n","    data = {'day1': [day1], 'day2': [day2], 'day3': [day3], 'day4': [day4], 'day5': [day5], 'tempVal': [tempVal], 'ageVal': [ageVal], 'Country': [countryName],\n","            'diff1': [diff1], 'diff2': [diff2], 'diff3': [diff3], 'diff4': [diff4]}\n","    df2 = pd.DataFrame(data)\n","    dfP.append(df2)\n","\n","dfP = pd.concat(dfP).reset_index(drop=True)\n","dfP.to_csv('Predict.csv')\n","\n","df = pd.read_csv('TrainTest.csv')\n","dfP = pd.read_csv('Predict.csv')\n","trainIpData = df[['day1', 'day2', 'day3', 'day4', 'day5', 'tempVal', 'ageVal', 'gammaFun', 'diff1', 'diff2', 'diff3', 'diff4']]\n","trainOpData = df['dayPredict']\n","PredictionData = dfP[['day1', 'day2', 'day3', 'day4', 'day5', 'tempVal', 'ageVal', 'diff1', 'diff2', 'diff3', 'diff4']]\n","#print(PredictionData.head())\n","predictions = TrainMdl (trainIpData, trainOpData, PredictionData)\n","dfP['NextPredictions'] = predictions\n","dfP['LatestNumberCases'] = dfP['day5']\n","dfP[['Country', 'LatestNumberCases', 'NextPredictions']].to_csv('CountryWisePredictions.csv')\n","pd.read_csv('CountryWisePredictions.csv').reset_index(drop=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["('Countries infected: ', 180, '/', 195)\n","('Final size of merged data (rows equal to number of countries to be processed): ', (140, 74))\n","('Row', 140, '| Col: ', 74)\n","Training starts ...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 25 is smaller than n_iter=100. Running 25 iterations. For exhaustive searches, use GridSearchCV.\n","  % (grid_size, self.n_iter, grid_size), UserWarning)\n","/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n"],"name":"stderr"},{"output_type":"stream","text":["('Train Data-set: Mean Rel Error in %: ', 6.4058262512955295)\n","('Validation Data-set : Mean Rel Error in %: ', 6.896060392326203)\n","-----------------------------------------------------------\n","('Train Data-set: Mean Rel Error in %: ', 6.426432035234445)\n","('Validation Data-set : Mean Rel Error in %: ', 6.630986165884675)\n","-----------------------------------------------------------\n","('Train Data-set: Mean Rel Error in %: ', 6.473505897877507)\n","('Validation Data-set : Mean Rel Error in %: ', 6.363688134775672)\n","-----------------------------------------------------------\n","('Train Data-set: Mean Rel Error in %: ', 6.486921271596977)\n","('Validation Data-set : Mean Rel Error in %: ', 6.076789494570316)\n","-----------------------------------------------------------\n","('Train Data-set: Mean Rel Error in %: ', 6.379030136542635)\n","('Validation Data-set : Mean Rel Error in %: ', 7.109480155114291)\n","-----------------------------------------------------------\n","('Train Data-set: Mean Rel Error in %: ', 6.5263153564729866)\n","('Validation Data-set : Mean Rel Error in %: ', 5.923857998745849)\n","-----------------------------------------------------------\n","('Train Data-set: Mean Rel Error in %: ', 6.3775444450007805)\n","('Validation Data-set : Mean Rel Error in %: ', 6.902193185017859)\n","-----------------------------------------------------------\n"],"name":"stdout"}]}]}